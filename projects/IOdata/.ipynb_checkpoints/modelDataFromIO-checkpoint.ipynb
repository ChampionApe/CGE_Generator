{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e983b2a3-b8ce-428b-8e5e-4dd827091260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No clean-up of work-folder\n"
     ]
    }
   ],
   "source": [
    "%run StdPackages.ipynb\n",
    "d['rawData'] = os.path.join(d['data'],'rawData69') # add\n",
    "d['processedData'] = os.path.join(d['data'],'processedData') # update to raw data folder\n",
    "os.chdir(d['py'])\n",
    "from loadIO import *\n",
    "import RAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3127bcdd-bc4e-4a4a-b5b6-e77e6f944904",
   "metadata": {},
   "source": [
    "# Create Stylized Model Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c798070-f5f8-48f4-a523-b5b44d45d328",
   "metadata": {},
   "source": [
    "The final data used for a CGE model varies based on specific framework. This shows a stylized version that we use in various UCPH projects. Specifically, we assume the following:\n",
    "* All equilibrium prices are normalized at 1.\n",
    "* Government consumption is aggregated into one type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c836ae1d-062b-4728-80df-a58c80e8af50",
   "metadata": {},
   "outputs": [],
   "source": [
    "IO = os.path.join(d['processedData'], 'IO68_2dur')\n",
    "name = 'stylizedCGEData'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31648897-2fff-4cde-9723-6491e0f33df4",
   "metadata": {},
   "source": [
    "This notebook shows by example how to aggregate IO data using a few simple mappings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12e60c4-ce41-4742-a9f6-427d22a8c272",
   "metadata": {},
   "source": [
    "*Load IO:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bd4f9d1-b7bb-41a0-add8-0ffe654cc95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = GpyDB(IO, name = name)\n",
    "ws = db.ws # work from this workspace as the main one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaec16e-d700-4523-b7c4-134febdfacd1",
   "metadata": {},
   "source": [
    "We only model total government consumption and not split it into the ```gc``` set that is included in the full data. We already have the total in the ```vD``` variable, so here we simply remove some components that we do not need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72adb961-bcf6-4474-a510-9308a594fc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "[db.series.database.pop(k) for k in ('gc','vC','vC_tax')];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cf5981-3029-4e21-ad18-3909b0c09c7b",
   "metadata": {},
   "source": [
    "Next, we remove all zero elements in variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31e68d70-bd3d-4bbc-acf1-8d6ce292b7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "[db.__setitem__(k, db(k)[db(k)!=0]) for k in db.getTypes(['var'])];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03f88f0-6046-43d2-8c67-d940d2b7d75f",
   "metadata": {},
   "source": [
    "Translate depreciation of durables to rates, distinguish between investments and durables (flow, stock) with investment good syntax ```I_x``` for durable ```x```. Define mapping ```dur2inv``` and subsets ```dur_p, inv_p```. Add investments and value of durables to the vector ```vD```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d80b902-d0f5-41a7-ba42-07a84dcef40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "db['rDepr'] = db('vD_depr')/db('vD_dur')\n",
    "db['dur_p'] = db('vD_dur').index.levels[db['vD_dur'].domains.index('n')]\n",
    "db['inv_p'] = db('dur_p').map(lambda x: f'I_{x}')\n",
    "db['dur2inv'] = pd.MultiIndex.from_arrays([db('dur_p'), db('inv_p').rename('nn')])\n",
    "db('vD_inv').index = db('vD_inv').index.set_levels(db('vD_inv').index.levels[db['vD_inv'].domains.index('n')].map(lambda x: f'I_{x}'), level = 'n')\n",
    "db['vD'] = db('vD_inv').combine_first(db('vD')).combine_first(db('vD_dur'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea462e7a-a8d9-48fe-9a1a-d7bb887687ba",
   "metadata": {},
   "source": [
    "Define subset of values to fix (at zero). Here, if the value is less than the absolute threshold value *and* less than relative value of the given sector:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6cf2a8-0674-4526-9e9a-dc4ed4abd81b",
   "metadata": {},
   "source": [
    "### 1. RAS adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af98e28-7677-43b2-bd67-4f36138d9aea",
   "metadata": {},
   "source": [
    "The RAS adjustment removes negative and (potentially) small values in the IO data. We remove small values to get a more sparse demand system (computational reasons) and negative values because standard CGE formulations require positive values. So, we can in principle skip this part, if we have sufficient computing power and a sufficiently flexible mathematical framework to handle negative values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04c4da6-d587-4abe-a02b-cc84b1579efa",
   "metadata": {},
   "source": [
    "We have three types of implementation here:\n",
    "* The simple RAS adjustment (```simpleRAS```): This performs matrix adjustments iteratively to make sure that the sum across rows (index $s$) and columns (index $n$) remain the same after we have imposed zero values in the IO matrix.\n",
    "* Minimize distortions (```absRAS```): This minimizes the sum of squared differences from new data values compared to original ones under the constraint that row sums (index $s$) and column sums (index $n$) remain the same. This is a qudratic programming (QP) problem that may be solved more efficiently with other solvers (e.g. KNITRO or CPLEX) than we have available here (CONOPT, which we prefer for CNS/NLP type models).\n",
    "* Minimize relative distortions (```shareRAS```): This minimizes the sum of squared differences from new data input *shares* instead. The ```shareRAS.pdf``` explains this in a bit more detail. This is also a QP problem, so it will probably be better to implement with CPLEX, but it works well even with CONOPT in a bit more aggregated data samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd2f7ec-9f4c-4d7a-bd68-c18c199187b3",
   "metadata": {},
   "source": [
    "#### ```simpleRAS```:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c0cf88-48e8-4f19-be3f-45126dd337ef",
   "metadata": {},
   "source": [
    "Define threshold (fix at zero if value is lower than this), the initial data that we want to adjust (```v0```), if there are any rows/columns that we do not *need* to balance, and the matrix with values fixed at zero (```vBar```):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02792d57-9011-41b9-a667-7e7ed9ff8d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1/100 # everything less than 1 million \n",
    "v0 = adj.rc_pd(db('vD'), ('and', [('or', [db('n_p'), db('n_F')]),\n",
    "                                  ('or', [db('s_p'), db('s_i')])]))\n",
    "leaveCols = db('n_F') # are there any type of goods that we do not need to balance\n",
    "leaveRows = None # are there any type of sectors that we do not need to balance\n",
    "vBar = v0[v0<threshold] * 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d221f01-a558-4733-9f82-510018fd3c99",
   "metadata": {},
   "source": [
    "This runs the simple RAS algorithm (it takes a bit of time and may require a lot of iterations to exit):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5cb734-89e8-47e0-9626-d188be972377",
   "metadata": {},
   "outputs": [],
   "source": [
    "vD = RAS.simpleRAS(v0, vBar, leaveCols = leaveCols, leaveRows = leaveRows, tol = 1e-6, iterMax = 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14618931-e723-40c4-a768-b70d5b6129de",
   "metadata": {},
   "source": [
    "#### ```absRAS```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8202a909-9ad7-4746-9526-5c906b9ab268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ras = RAS.absRAS(v0, vBar, ws = ws, leaveCols = leaveCols)\n",
    "# ras.db['adjTerm'] = adj.rc_pd(vD, ras.db('active'))/ras.db('vD0')-1\n",
    "# ras.db.mergeInternal() # write gdx file based on python symbols\n",
    "# job = ws.add_job_from_string(ras())\n",
    "# job.run(databases = ras.db.database)\n",
    "# vD = GpyDB(job.out_db)('vD') # get solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e35a91-9a1a-44d5-871c-fc453584c534",
   "metadata": {},
   "source": [
    "#### ```shareRAS```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7a050f-c233-4110-9a1c-58c61eab3596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 1 # only remove negative values and less than values less than 100,000 \n",
    "# rasSettings = IOfunctions.standardCleanSettings(dbi, threshold) #\n",
    "# sols = {}\n",
    "# for k,v in rasSettings.items():\n",
    "#     ras = shareRAS(v['v0'], v['vBar'], ws = ws, **v['kwargs'])\n",
    "#     job = ws.add_job_from_string(ras())\n",
    "#     ras.db.mergeInternal()\n",
    "#     job.run(databases = ras.db.database)\n",
    "#     sols[k] = GpyDB(job.out_db) # store databases "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8c142f-71f9-416a-8bad-2fbd796a7010",
   "metadata": {},
   "source": [
    "*Merge things back up again:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bef161-4891-43fc-b2b5-302b8f1a96bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vD_full = vD.combine_first(db('vD'))\n",
    "vD_full = vD_full[vD_full!=0] # remove zero values again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb0c9f8-be04-49aa-8553-c2664212bd6d",
   "metadata": {},
   "source": [
    "*Remove residual income category (we don't currently use this in the model, this will enter the return on durables instead):*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcee237-c582-4ae7-ac49-99b70abac7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "db['vD'] = adj.rc_pd(vD_full, ('not', pd.Index(['resIncome'], name = 'n')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5458ca-4a77-4601-8cd9-ed33d60446b3",
   "metadata": {},
   "source": [
    "### 2. Create other variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f8f98d-22ab-4f7f-9053-068f5d079056",
   "metadata": {},
   "source": [
    "Next, we create other model variables: Value of supply - and then distinguish between prices and quantities (we assume that all prices = 1 in baseline year at least):\n",
    "* The value of supply ```vS[t,s,n]``` is defined for domestic production and investment sectors by summing over demand by summing over demand from all other sectors. The default options is here that $s = n$ as each sector only produces a single output. \n",
    "* The equilibrium price ```p[t,n]``` is set to $1$ for each good $n$. This is defined for all domestic and foreign goods.\n",
    "* For the durable types, we set the quantity $qD[t,s,n] = vD[t,s,n]$, then we add the price vector ```pD_dur[t,s,n]``` from the static user cost term:\n",
    "$$\\begin{align}\n",
    "    \\text{staticUserCost}_K = p_I \\left(\\dfrac{R}{1+\\pi}+\\delta_k-1\\right),\n",
    "\\end{align}$$\n",
    "    where $p_I$ is the price on the investment good that corresponds to durable $K$, $R$ is the real interest rate factor, $\\pi$ is the inflation rate, and $\\delta_k$ is the depreciation rate.\n",
    "* Finally, we set $qD[t,s,n] = vD[t,s,n] / p[t,n]$ for non-durables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d80fdb-1648-47b5-977f-e019053782ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "db['R_LR'] = 1.03\n",
    "db['infl_LR'] = 0.02\n",
    "model_vS(db)\n",
    "model_p(db)\n",
    "model_durables(db, db('R_LR'), db('infl_LR'))\n",
    "model_quantNonDurables(db) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783bcf2b-632a-4af1-b858-8d5343033798",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Create other subsets and mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a711d3f-2605-4e33-b9ab-4a5cf97312c4",
   "metadata": {},
   "source": [
    "Subsets of goods/sectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35636a2-9e42-415f-b37b-c8a64e562fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "db['nEqui'] = db('vS').index.droplevel('s').unique() # what goods require an equilibrium condition\n",
    "db['d_qS'] = db['vS'].index \n",
    "db['d_qD'] = adj.rc_pd(db('vD'), db('nEqui')).index \n",
    "db['d_qSEqui'] = adj.rc_pd(db['d_qS'].vals, ('not', db('s_HH'))) # Subset of qS values to be endogenized in general equilibrium\n",
    "db['d_pEqui'] = pd.Index(['L'], name ='n') # Subset of prices to be endogenized in general equilibrium "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f104894-60ec-434a-8221-dd6ca1a2bfd7",
   "metadata": {},
   "source": [
    "#### 3.1. Trade mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f1e163-beca-4345-a37c-f0d382fa0f2c",
   "metadata": {},
   "source": [
    "Define the mappings:\n",
    "* ```dom2for[n,nn]```: Mapping from domestic to the equivalent foreign goods (with syntax ```x,x_F```).\n",
    "* ```dExport[t,s,n]```: Foreign sectors' demand for domestic goods.\n",
    "* ```dImport[t,s,n,nn]```: sector, domestic good, foreign good combinations in data - i.e. where a sector demands both domestic and foreign type of product.\n",
    "* ```dImport_dom[t,s,n]```: sector, domestic good combination (s,n) where the sector only demands the domestic and not the corresponding foreign good.\n",
    "* ```dImport_for[t,s,n]```: sector, foreign good combinations (s,n) where the sector only demand the foreign and not the corresponding domestic good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad9f4d5-9a70-48ae-934e-8ea249dcbe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "db['dom2for'] = pd.MultiIndex.from_arrays([db('n_p').sort_values(), db('n_F').sort_values().rename('nn')])\n",
    "db['dExport'] = adj.rc_pd(db('vD'), db('s_f')).index\n",
    "vD_dom = stdSort(adjMultiIndex.applyMult(adj.rc_pd(db('vD'), db('n_p')), db('dom2for')))\n",
    "vD_for = adj.rc_pd(db('vD'), db('n_F')).rename_axis(index= {'n':'nn'})\n",
    "db['dImport'] = stdSort(adj.rc_pd(vD_dom, vD_for)).index\n",
    "db['dImport_dom'] = adj.rc_pd(vD_dom, ('not', vD_for)).droplevel('nn').index\n",
    "db['dImport_for'] = adj.rc_pd(vD_for, ('not', db('dImport'))).rename_axis(index = {'nn':'n'}).index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9f5efe-34bc-4292-954c-3b47f344fd26",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe10a83-b709-44d0-a943-715a5558f232",
   "metadata": {},
   "outputs": [],
   "source": [
    "AggDB.readSets(db) # define sets from variables/parameters defined throughout\n",
    "db.export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
