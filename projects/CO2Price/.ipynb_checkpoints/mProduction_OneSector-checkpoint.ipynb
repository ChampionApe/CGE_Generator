{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d9f4c0d-3d58-46d2-a5d9-a03878086fb0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdb777d-1147-47c1-8c85-5a196493a30e",
   "metadata": {},
   "source": [
    "## 1. Data/settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186a4bee-d164-46a0-b8fb-4cc23de12fc3",
   "metadata": {},
   "source": [
    "If the local variable $t$ has been defined already, the notebook is running from another notebook. If this is not the case, a number of \"local\" methods have to be carried out before solving the model (e.g. setting up the relevant IO data set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b580d382-d006-434c-a5d8-93ffe50ee081",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_up = True\n",
    "%run StdPackages.ipynb\n",
    "name, t = 'full', 2019\n",
    "ws = gams.GamsWorkspace(working_directory=d['work']) # specify where you want to run the GAMS models from (here the repository referred to in d['work'])\n",
    "with open(f\"{d['processedData']}\\\\glob_{t}\",\"rb\") as file: # load global settings anmed glob_name\n",
    "    glob=pickle.load(file)\n",
    "db_IO = GpyDB(pickle_path = os.path.join(d['processedData'], f'{name}_{t}')) # load IO database named IO_name\n",
    "addTimeToDb(db_IO, glob.db['t'].vals, exceptions = ['sigma'])\n",
    "module = '_'.join([name,str(t),'P'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4911d517-334b-406d-bcaa-8b5b33beaa8f",
   "metadata": {},
   "source": [
    "*Pick out a sector:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0f6c758-dd44-43b5-81d1-5be0c5a51e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_IO0 = db_IO.copy() # create copy\n",
    "db_IO1 = db_IO.copy() # we need an extra one here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1ae681-4aeb-45fb-bd55-07562a345907",
   "metadata": {},
   "source": [
    "Add durable prices (for now, to solve static calibration):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbd9e395-4a38-4274-aa56-b92d49cdda7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_IO0['pD'] = db_IO0.get('pD_dur').combine_first(db_IO0.get('pD'))\n",
    "db_IO0['p'] = db_IO0.get('pD_dur').groupby(['t','n']).mean().combine_first(db_IO0.get('p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32344c55-3d38-4c5c-82ef-a1f90c0d666b",
   "metadata": {},
   "source": [
    "## 2. Initial values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b8c3e6-e1cb-4dc6-baee-dc623648ac4f",
   "metadata": {},
   "source": [
    "Set up nesting tree using the nesting structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66076d50-e14a-4a34-9ef8-14ea4b214fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "s = db_IO.get('s_p')[i:i+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b898b3fd-4149-44ee-a683-c9577653e271",
   "metadata": {},
   "outputs": [],
   "source": [
    "nest = adj.rc_pd(db_IO.get('nestProduction'), s) # test model with only one of the sectors\n",
    "tree = nestingTree.tree(name = f'{module}_ces', tree = nest.to_list()) # individual tree\n",
    "\n",
    "# tree = nestingTree.tree(name = f'{module}_ces', tree = db_IO.get('nestProduction').to_list()) # individual tree\n",
    "Tree = nestingTree.aggTree(name = module, trees = {tree.name: tree})(namespace = {str(n)+'_input': n for n in db_IO.get('n')})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5272bb7c-237c-4f0c-8f58-537ac39f25f0",
   "metadata": {},
   "source": [
    "Initialize production module, without any durables at first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07fa7b08-dfdf-47b3-be65-7d1969f74bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = mProductionEmissions.Production(tree=Tree, glob = glob) # initialize module from nesting tree and global settings\n",
    "aggregateDB.subset_db(db_IO0, Tree.db.get('s')) # goes through all symbols in db_IO and only keep the elements that are in the set 's' from Tree.db\n",
    "aggregateDB.subset_db(db_IO0, Tree.get('n')) # goes through all symbols in db_IO and only keep the elements that are in the set 'n' from Tree.db\n",
    "robust.robust_merge_dbs(P.s.db, db_IO0, priority = 'second') # Merge IO data into the database of the module; if a symbol is in both, prioritize records from the second database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020f225e-3e66-495a-a7f7-d0dd9920da03",
   "metadata": {},
   "source": [
    "Add value shares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d40e7735-af26-4a6f-a2ca-2df45a7bef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = valueShares.valueShares(Tree, db_IO0)\n",
    "v.compile() # set up model structure, and make sure to initialize symbols if they are not yet defined in the database \n",
    "v.write(); # write GAMS code used for the model\n",
    "m = v.run(exportTo = d['work'],ws=ws) # solve the \"model\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b8317b-41a7-4270-8eab-0bb6c291d45e",
   "metadata": {},
   "source": [
    "Use value shares to initialize variables:\n",
    "* Outputs and inputs are provided by IO data.\n",
    "* For intermediate goods, assume a price of 1 (default option in the class, so we don't have to do anything) and set value share = quantity.\n",
    "* Set share parameters to the ones identified by value share system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d0d4fd6-911f-40a2-857c-1f74e6e41697",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpyDB.GpyDBs_AOM_Second(P.s.db, gpy(adj.rc_pd(m.out_db.get('vD'), P.get('int')).rename('qD'))) # set intermediate goods levels\n",
    "gpyDB.GpyDBs_AOM_Second(P.s.db, gpy(m.out_db.get('mu').xs(P.get('t0')[0]).rename('mu'))) # set intermediate goods levels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b01cc5-8a20-49c5-8c1b-a0db6f78d7df",
   "metadata": {},
   "source": [
    "### 3. Static calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "132e5f6f-c3e1-4806-b52a-e726ed777423",
   "metadata": {},
   "outputs": [],
   "source": [
    "P.compile(initDB=True) # set up model structure, and make sure to initialize symbols if they are not yet defined in the database (initDB = True)\n",
    "P.s.setstate('C') # set to calibration state\n",
    "P.write(); # write GAMS code\n",
    "mStatic = P.run(exportTo = d['work'],ws=ws,**{'cns': 'CONOPT4'}) # solve the model using CONOPT4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda834c7-a7f2-44f8-9c9e-27d4fd323c00",
   "metadata": {},
   "source": [
    "### 4. Dynamic calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7546ce83-3c02-451e-b657-ce0bcfc269ac",
   "metadata": {},
   "source": [
    "Initialize module with static calibration as data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5624ad49-2a85-44fd-abbe-a8fa3b2caf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = mProductionEmissions.Production_ExoMu(tree = Tree, glob = glob)\n",
    "robust.robust_merge_dbs(P.s.db, mStatic.out_db.getTypes(['variable','scalar_variable']), priority = 'second')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea28e422-7f47-49b5-8d10-c5faa381fda1",
   "metadata": {},
   "source": [
    "Add durables and remove ```MData``` (includes years that are not used in the model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e161ca4a-98d4-4ec0-9815-1f9156f915e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "P.s.db['MData'] = adj.rc_pd(P.get('MData'),P.get('t'))\n",
    "aggregateDB.readSets(P.s.db) # this makes sure that all necessary sets are defined in the database\n",
    "P.addDurables(dur = db_IO1.get('dur_p'), dur2inv = db_IO1.get('dur2inv'), f = 'sqrAdjCosts')\n",
    "P.initDurables() # adjust to steady state-like model\n",
    "P.compile(initDB=True) # set up model structure\n",
    "P.write(); # write GAMS code\n",
    "# mBaseline = P.run(exportTo = d['work'],ws=ws,**{'cns': 'CONOPT4'}) # solve the model using CONOPT4; baselinea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc37f53-66ba-4bbf-a4a7-99bd321fc377",
   "metadata": {},
   "source": [
    "Solve dynamic calibration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bd224e8-1ce8-40a3-87f4-d1e573f3e644",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregateDB.subset_db(db_IO1, P.get('t0')) # Only keep IO data on baseline year\n",
    "mCalib, cp = P.sneakyCalib(db_IO1, exportTo = d['work'],ws=ws, loop_kwargs = {'n':10}, **{'cns': 'CONOPT4'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
