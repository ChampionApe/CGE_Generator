{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9be6c37e-f771-49c2-b9b3-f31d4bc4f2d5",
   "metadata": {},
   "source": [
    "# Household"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a236a6e1-11bf-49dc-978d-0b88fb4ef056",
   "metadata": {},
   "source": [
    "## 1. Data/settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfabc47-3927-4e7e-a811-742c2eefd097",
   "metadata": {},
   "source": [
    "If the local variable $t$ has been defined already, the notebook is running from another notebook. If this is not the case, a number of \"local\" methods have to be carried out before solving the model (e.g. setting up the relevant IO data set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3154be58-76c4-4bdf-899d-dd174426d905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file _gams_py_gdb13.gdx is still active and was not deleted.\n",
      "The file _gams_py_gdb16.gdx is still active and was not deleted.\n",
      "The file _gams_py_gdb17.gdx is still active and was not deleted.\n",
      "The file _gams_py_gdb18.gdx is still active and was not deleted.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    t = t\n",
    "except NameError:\n",
    "    clean_up = True\n",
    "    %run StdPackages.ipynb\n",
    "    name, t = 'm', 1990\n",
    "    ws = gams.GamsWorkspace(working_directory=d['work']) # specify where you want to run the GAMS models from (here the repository referred to in d['work'])\n",
    "    with open(f\"{d['processedData']}\\\\glob_{t}\",\"rb\") as file: # load global settings anmed glob_name\n",
    "        glob=pickle.load(file)\n",
    "    db_IO = GpyDB(pickle_path = os.path.join(d['processedData'], f'{name}_{t}')) # load IO database named IO_name\n",
    "    addTimeToDb(db_IO, glob.db['t'].vals, exceptions = ['sigma'])\n",
    "module = '_'.join([name,str(t),'HH'])\n",
    "db_IO0 = db_IO.copy() # create copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d848ded3-7129-4dc7-85c6-edafce085ac5",
   "metadata": {},
   "source": [
    "## 2. Initial values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb24b13-863a-44a7-9894-9fbc81ead550",
   "metadata": {},
   "source": [
    "Set up nesting tree using the nesting structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3964480-7c2a-4068-af69-e27d2cbc6c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = nestingTree.tree(name = f'{module}_ces', tree = db_IO.get('nestHH').to_list()) # individual tree\n",
    "Tree = nestingTree.aggTree(name = module, trees = {tree.name: tree})(namespace = {str(n)+'_input': n for n in db_IO.get('n')})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea42a773-394d-4962-9231-203c9123793c",
   "metadata": {},
   "source": [
    "## 3. Run module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52d31bd-0d6a-41e5-b6ea-afe9d5a08876",
   "metadata": {},
   "source": [
    "*1. Initialize production module, without any durables at first:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4982e5c5-cbb2-476a-bb52-9cb328f2757c",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = mHouseholds.staticConsumer(tree = Tree, glob = glob, kwargs = {'L2C': db_IO.get('L2C')})\n",
    "aggregateDB.subset_db(db_IO0, H.get('s')) # goes through all symbols in db_IO and only keep the elements that are in the set 's' from Tree.db\n",
    "aggregateDB.subset_db(db_IO0, H.get('n')) # goes through all symbols in db_IO and only keep the elements that are in the set 'n' from Tree.db\n",
    "# robust.robust_merge_dbs(H.s.db, db_IO, priority = 'second')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e496987-8f82-40aa-b059-e77d0266a9aa",
   "metadata": {},
   "source": [
    "*2. Add value shares:*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fed66c-ec33-442a-b229-b90503b82aed",
   "metadata": {},
   "source": [
    "Value shares for nesting part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1da21a18-75f6-4b47-810a-115fb62980ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = valueShares.SimpleRamsey(Tree, db_IO0)\n",
    "v.compile() # set up model structure, and make sure to initialize symbols if they are not yet defined in the database \n",
    "v.write(); # write GAMS code used for the model\n",
    "m = v.run(exportTo = d['work'],ws=ws) # solve the \"model\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeadd8c-2888-4a6d-a348-7da8c95c9105",
   "metadata": {},
   "source": [
    "Use value shares to initialize variables:\n",
    "* Outputs and inputs are provided by IO data.\n",
    "* For intermediate goods, assume a price of 1 (default option in the class, so we don't have to do anything) and set value share = quantity.\n",
    "* Set share parameters to the ones identified by value share system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf2dc71e-1688-48bb-be7c-222d270daf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpyDB.GpyDBs_AOM_Second(H.s.db, gpy(adj.rc_pd(m.out_db.get('vD'), H.get('int')).rename('qD'))) # set intermediate goods levels\n",
    "gpyDB.GpyDBs_AOM_Second(H.s.db, gpy(m.out_db.get('mu').xs(H.get('t0')[0]).rename('mu'))) # set share parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d469ee-f905-4c54-99cb-4028fc29a7e8",
   "metadata": {},
   "source": [
    "Add the frisch parameter as a target in the IO database if we want to have an intensive margin labor elasticity in there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaeb559c-1bf0-4026-b509-638dda6fb2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_IO['frisch'] = pd.Series(0.25, index = H.get('labor'), name = 'frisch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c317ba-3299-490a-a781-3dbb4c5fcfc8",
   "metadata": {},
   "source": [
    "Use sneaky calibration method to solve and calibrate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afdc8946-09d4-4817-8de9-2447c1395771",
   "metadata": {},
   "outputs": [],
   "source": [
    "H.compile(initDB=True)\n",
    "H.write();\n",
    "mCalib, cp = H.sneakyCalib(db_IO.copy(), ws = ws, loop_kwargs = {'n': 25}, **{'cns': 'CONOPT4'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660d1103-07e5-4314-aa3d-6e190398a80e",
   "metadata": {},
   "source": [
    "### 4. Export "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5da80e9-46c2-4306-86c2-e4a22403ab16",
   "metadata": {},
   "source": [
    "*Use data from the calibration step in the main database. The ```sneakyCalib``` method defines some new, auxiliary symbols - these are not used.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85208245-b2e5-48c7-a903-0afcc06c4c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "[gpyDB.GpyDBs_AOM_Second(H.s.db, mCalib.out_db[k]) for k in H.s.db.symbols];\n",
    "H.s.setstate('B')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0e1c76-f6ed-4648-b609-c6ccd88a0a7b",
   "metadata": {},
   "source": [
    "Export:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1aba6fe2-5b33-4514-9ff6-5a0df23f7058",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(d['modules'], H.name), \"wb\") as file:\n",
    "    pickle.dump(H,file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
