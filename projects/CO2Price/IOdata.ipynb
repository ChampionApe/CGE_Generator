{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec444979-1fb6-4a85-b51c-2029221de639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file _gams_py_gdb0.gdx is still active and was not deleted.\n",
      "The file _gams_py_gdb1.gdx is still active and was not deleted.\n",
      "The file _gams_py_gdb13.gdx is still active and was not deleted.\n",
      "The file _gams_py_gdb17.gdx is still active and was not deleted.\n",
      "The file _gams_py_gdb20.gdx is still active and was not deleted.\n",
      "The file _gams_py_gdb4.gdx is still active and was not deleted.\n"
     ]
    }
   ],
   "source": [
    "clean_up=True\n",
    "%run StdPackages.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f119c0f-e2d0-467f-9029-a62b6d3673b7",
   "metadata": {},
   "source": [
    "# Set up data for BabyGreenReform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8229da01-6f1b-49ed-b767-3d550edc1383",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(d['py'])\n",
    "from loadIO import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb073eed-6508-4fba-b519-4747cb45cd5f",
   "metadata": {},
   "source": [
    "*Basic settings:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a68186fb-78bb-4658-8b00-090f2f9366f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = 1990 # initial year\n",
    "tE = 2019 # terminal year\n",
    "file_k = os.path.join(d['rawData'], 'Durables.xlsx') # xlsx file with data on durables\n",
    "file_m = os.path.join(d['rawData'], 'Emissions.xlsx') # xlsx file with data on emissions\n",
    "file_mappings = os.path.join(d['rawData'], 'Mappings.xlsx') # mappings for aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68ee660-f292-4e47-b17d-459a9e0ac2da",
   "metadata": {},
   "source": [
    "Global settings -- e.g. what are the time horizon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63be8005-e946-4088-a512-0098c48f7f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "glbls = {t: gmsPyGlobals.SmallOpen(kwargs_vals = {'t': range(t,t+100)}) for t in range(t0,tE+1)} # global settings used throughout; interest rates, long run growth rates, time index etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2edb11-c49a-4686-9efd-9b6369b824b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Read in data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5022d8-f951-4e09-8237-8444bd568503",
   "metadata": {},
   "source": [
    "### 1.1. Data on durables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb66eab3-068a-4491-a99e-26b9d03fdd34",
   "metadata": {},
   "source": [
    "*Mapping of names:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03075f3a-4e1d-4a78-9ad1-ced1a29250b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "namesToInv = {'Boliger': '5110', \n",
    "              'Andre bygninger': '5121',\n",
    "              'Anlæg': '5122',\n",
    "              'Transportmidler': '5131',\n",
    "              'ICT udstyr, andre maskiner og inventar samt våbensystemer': '513x',\n",
    "              'Stambesætninger mv.': '5150',\n",
    "              'Intellektuelle rettigheder': '517x'}\n",
    "namesInvVariables = {'AN.11 Faste aktiver, nettobeholdning, primo året': 'K',\n",
    "                     'P.51c Forbrug af fast realkapital': 'Depr1',\n",
    "                     'P.51g Faste bruttoinvesteringer': 'I',\n",
    "                     'K.3 Tab ved katastrofer': 'Depr2',\n",
    "                     'K.7 Nominelle kapitalgevinster og -tab': 'Depr3',\n",
    "                     'AN.11 Faste aktiver, nettobeholdning ultimo året': 'Kp1'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7780a5-b938-4674-a3e7-760d447e0a31",
   "metadata": {},
   "source": [
    "Durables data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b35592b4-528d-49c4-899c-bf144c91d073",
   "metadata": {},
   "outputs": [],
   "source": [
    "dur = getDurables(file_k, 'NABK69', namesToInv, namesInvVariables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacb8d4d-b3b3-4b8c-a653-02b5c869011d",
   "metadata": {},
   "source": [
    "### 1.2. Read emissions data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eba0db3d-fc05-40ef-9376-b6d10ddab2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions = emissionsReadData(file_m) # NB: This rescales emission taxes to 1000 DKK - as this is the standard unit used for taxes in the main IO table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5622de9a-df53-42ae-ba4f-808be2707c5d",
   "metadata": {},
   "source": [
    "Emissions on sectoral level is defined only for \"emissions from the Danish economy\" and includes things like international shipping and does not include the LULUCF sector. Also, we only include emissions from the production sectors (and not direct emissions e.g. from households). This scales emissions such that we follow the \"inclusive LULUCF\"-like measure that CO2 targets are formulated in terms of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f0dc121-56d4-48df-a208-6c50a9408805",
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions['qCO2'] = emissions['qCO2'] * (emissions['totalEmissions'] / emissions['qCO2'].groupby('t').sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29c8bd1-38af-4fc2-87ca-6a715a0bb77d",
   "metadata": {},
   "source": [
    "Add to all globals, the level of emissions in 1990:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11d9d0ea-9e52-4d0c-bfc5-3351986392ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "[glbl.db.__setitem__('M1990', gpy(emissions['totalEmissions'].xs('1990'), **{'name': 'M1990'})) for glbl in glbls.values()];\n",
    "[glbl.db.__setitem__('MData', gpy(emissions['totalEmissions'].set_axis(emissions['totalEmissions'].index.astype(int)),\n",
    "                                  **{'name': 'MData'})) for glbl in glbls.values()];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dd3053-874c-4c32-b49a-2284d0fd07b2",
   "metadata": {},
   "source": [
    "Add variable for cumulative overshoot compared to targets:\n",
    "* Version 1: Accumulated overshoot is not eliminated (carried across regimes). Only exception is new regime around $t=2020$ where new policy targets reflect attempt to eliminate historical overshoot.\n",
    "* Version 2: Accumulated overshoot is eliminated when entering a new policy regime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55d0c496-d052-48ea-89a6-79ce2fa9db87",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = emissions['qCO2'].groupby('t').sum()\n",
    "M = M.set_axis(M.index.astype(int))\n",
    "Mnorm = M / M.xs(1990)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf94a08-784e-4121-b4cb-d8b2b0824f08",
   "metadata": {},
   "source": [
    "Targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd62efee-f881-4c64-bddb-f267e5cd942f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_R1 = pd.Series(np.linspace(1, 0.8, 16), index = pd.Index(range(1990, 2006), name = 't')) * M.xs(1990)\n",
    "target_V1R2 = pd.Series(np.linspace(0.8, 0.79, 7), index = pd.Index(range(2005,2011+1), name = 't')) * M.xs(1990)\n",
    "target_V1R3 = pd.Series(np.linspace(0.79, 0.6, 10), index = pd.Index(range(2011,2020+1), name = 't')) * M.xs(1990)\n",
    "target_V1R4 = pd.Series(np.linspace(0.6, 0.3, 11), index = pd.Index(range(2020, 2031), name = 't')) * M.xs(1990)\n",
    "\n",
    "target_V2R2 = pd.Series(np.linspace(Mnorm.xs(2005), 0.79, 7), index = target_V1R2.index) * M.xs(1990)\n",
    "target_V2R3 = pd.Series(np.linspace(Mnorm.xs(2011), 0.6, 10), index = target_V1R3.index) * M.xs(1990)\n",
    "target_V2R4 = pd.Series(np.linspace(Mnorm.xs(2020), 0.3, 11), index = target_V1R4.index) * M.xs(1990)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d213483d-0110-4a0b-989c-cba57128479e",
   "metadata": {},
   "source": [
    "Cumulative overshoot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6fe63b2-ecce-4910-b268-88f57bb8c3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "overshoot_R1 = (M-target_R1).dropna().cumsum()\n",
    "overshoot_V1R2 = (M-target_V1R2.loc[2006:]).dropna().cumsum()+overshoot_R1.xs(2005)\n",
    "overshoot_V1R3 = (M-target_V1R3.loc[2012:]).dropna().cumsum()+overshoot_V1R2.xs(2011)\n",
    "overshoot_V1 = pd.concat([overshoot_R1, overshoot_V1R2, overshoot_V1R3], axis = 0)\n",
    "\n",
    "overshoot_V2R2 = (M-target_V2R2.loc[2005:2010]).dropna().cumsum()\n",
    "overshoot_V2R3 = (M-target_V2R3.loc[2011:]).dropna().cumsum()\n",
    "overshoot_V2 = pd.concat([overshoot_R1.loc[:2004], overshoot_V2R2, overshoot_V2R3], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251d2278-4533-47c4-9f4c-88967e2d4106",
   "metadata": {},
   "source": [
    "Add to globals data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b121dc4c-807f-41b0-8ae5-9b258d8d7cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(t0, tE+1):\n",
    "    glbls[t].db['qOS_V1'] = gpy(overshoot_V1.xs(t), **{'name': 'qOS_V1'})\n",
    "    glbls[t].db['qOS_V2'] = gpy(overshoot_V2.xs(t), **{'name': 'qOS_V2'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9ec0cd-dce2-4a1b-8f24-3f8403806e05",
   "metadata": {},
   "source": [
    "### 1.3. IO data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfbeca8-66af-4c1f-883a-0147822f74a4",
   "metadata": {},
   "source": [
    "IO data is a bit more complicated, as they are not naturally arranged as time series (each year is a large matrix). As we already have IO data functions available that deals with the data year-by-year, we loop over the relevant years ad extract and adjust relevant data along the way.\n",
    "\n",
    "*The standard settings for doing this with NR69 detailed dataset in English:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e0a44f8-7648-4f86-85db-764a7bbe353e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs_v = {} \n",
    "kwargs_v['rowMarkers'] = {'P': {'ref': 'Danish production', 'offset': {}},\n",
    "                          'M': {'ref': 'Imports', 'offset': {}},\n",
    "                          'OT':{'ref': 'Other Foreign Transactions', 'offset': {}},\n",
    "                          'PI':{'ref': 'Primary Factors', 'offset':{}},\n",
    "                          'TI':{'ref': 'Input / final demand, purchasers prices', 'offset':{}},\n",
    "                          'PV':{'ref': 'Total Output', 'offset': {}}\n",
    "                         }\n",
    "kwargs_v['colMarkers'] = {'In': {'ref': 'Input in production (Transaction code 2000)', 'offset': {'colE':-7}},\n",
    "                          'C' : {'ref': 'GFCF', 'offset': {'col0': -5, 'colE': -5}},\n",
    "                          'G_NPISH': {'ref': 'GFCF', 'offset': {'col0': -4, 'colE': -4}},\n",
    "                          'G_MVPC':  {'ref': 'GFCF', 'offset': {'col0': -3, 'colE': -3}},\n",
    "                          'G_NMVPC': {'ref': 'GFCF', 'offset': {'col0': -2, 'colE': -2}},\n",
    "                          'G_CPC':   {'ref': 'GFCF', 'offset': {'col0': -1, 'colE': -1}},\n",
    "                          'I': {'ref': 'GFCF', 'offset':{}},\n",
    "                          'Other': {'ref': 'Other uses', 'offset': {}},\n",
    "                          'T': {'ref': 'Total'}}\n",
    "kwargs_v['category'] = {'taxCategories': ['Product taxes (excl. VAT)', 'VAT', 'Other production taxes'],\n",
    "                        'wageCategory' : 'Wages and Salaries',\n",
    "                        'residualIncomeCategory': 'Gross Surplus and mixed income',\n",
    "                        'itoryCategories': ['5300','5200'],\n",
    "                        'exportCategory': '6000'}\n",
    "kwargs_i = {}\n",
    "kwargs_i['rMarker'] = 'Total investment, purchase prices'\n",
    "kwargs_i['cMarkers'] = ['Investing industries', 'Total']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b4ca06-7ea1-4634-932a-5e1652213c6e",
   "metadata": {},
   "source": [
    "Loop through the relevant years and create databases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a884d4d6-316a-4110-86a8-95ba0dc68d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs = {}\n",
    "for t in range(t0, tE+1):\n",
    "    # Load data:\n",
    "    name = f'IO{t}'\n",
    "    file_v = os.path.join(d['rawData'], f'InputOutput_{t}.xlsx')\n",
    "    I = IOfunctions_withoutDurables.readIO(name = name, file_v = file_v, kwargs_v = kwargs_v)\n",
    "    I() # go through standard methods to extract and define data\n",
    "    addDurablesToDb(I.db, dur, t) # add durables data\n",
    "    addEmissionsToDb(I.db, emissions, t) # add emissions data\n",
    "    [I.db.__setitem__(k, I.db.get(k)/1000) for k in ('vTax','TotalTax','vD','vC','vC_tax')]; # Rescale variables\n",
    "    I.cleanOtherForeignTransactions() # Clean up other foreign transactions\n",
    "    aggregateDB.readSets(I.db) # add sets\n",
    "    I.db['n'] = adj.rc_pd(I.db.get('n'), ('not', I.db.get('n_Fother'))) # Clean up\n",
    "    del(I.db.series['n_Fother'])\n",
    "    [I.db.__setitem__(k,IOfunctions.stdSort(v.vals)) for k,v in I.db.getTypes(['variable','parameter']).items()]; # Sort indices:\n",
    "    dbs[t] = I.db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79c2ec0-0bf8-4864-add4-ee6cea408ea3",
   "metadata": {},
   "source": [
    "## 3. Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb1b6c9-9b10-4e94-bd73-cacb69fce71e",
   "metadata": {},
   "source": [
    "We aggregate from 7 types of durables to 2 (iB and iM). This means aggregation of the sector index ($s$) and the goods index ($n$). Note that we refer to the durables as ```iB,iM``` and the corresponding investment goods as ```I_iB, I_iM``` such that:\n",
    "$$\\begin{align}\n",
    "    iB_{t+1} = iB_t(1-\\delta)+I\\_iB_{t}\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08e038c-eecf-4368-9f04-b7aad541c77d",
   "metadata": {},
   "source": [
    "*Load mapping from 7 to 2 investment types:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47107bd1-9bab-4fb6-8289-47a19ab2df38",
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_mappings = read.simpleLoad(file_mappings)\n",
    "auxMaps = read.maps(wb_mappings['AuxMaps'])\n",
    "mDur = auxMaps['inv7toinvGR'].vals\n",
    "mDur = mDur.set_levels(mDur.levels[0].astype(str), level = 0) # force first index level to string format\n",
    "# m = auxMaps['s69tosGR'].vals # real definition\n",
    "m = auxMaps['s69tosSmall'].vals # use 2-sector definition\n",
    "m = m.set_levels(m.levels[0].astype(str), level = 0) # force first index level to string format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2e29a0-dc78-44f5-aacd-85eccd5238a6",
   "metadata": {},
   "source": [
    "*Create full sector and goods mappings:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf818dcd-7fab-4926-8bff-09cb01cb3b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_s = m.union(pd.MultiIndex.from_frame(mDur.to_frame(index=False).assign(temp = lambda x: 'I_'+x['nn'])[['n','temp']]).rename(['s','ss']))\n",
    "m_sector = m_s.union(pd.MultiIndex.from_arrays([adj.rc_pd(dbs[t].get('s'), ('not', m_s.levels[0])), \n",
    "                                                adj.rc_pd(dbs[t].get('s'), ('not', m_s.levels[0])).rename('ss')])) # for sectors not in the mapping --> use neutral mapping (x,x)\n",
    "m_goods = m.rename(['n','nn']).union(m.set_levels([level.astype(str)+'_F' for level in m.levels]).rename(['n','nn'])).union(mDur)\n",
    "m_goods = m_goods.union(pd.MultiIndex.from_arrays([adj.rc_pd(dbs[t].get('n'), ('not', m_goods.levels[0])),\n",
    "                                                   adj.rc_pd(dbs[t].get('n'), ('not', m_goods.levels[0])).rename('nn')])) # for goods not in the mapping --> use neutral mapping (x,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d9f73e-6abc-46c1-bcef-e88c3d6f44d0",
   "metadata": {},
   "source": [
    "*Apply aggregation to all databases*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4afa788c-b852-4761-bbc5-2c4a38c2897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(t0, tE+1):\n",
    "    aggregateDB.aggDB(dbs[t], m_sector)\n",
    "    aggregateDB.aggDB(dbs[t], m_goods)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29c713f-aa53-4d58-b667-4846ba80be4f",
   "metadata": {},
   "source": [
    "## 4. Clean up taxes, government consumption, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e2e816-6169-45ee-ae16-53e27b1bd0ae",
   "metadata": {},
   "source": [
    "A wee bit of clean-up of the relevant data here:  We only use the total government consumption, and not the consumption split onto the many types ```gc```. This is already recorded in the ```vD``` variable. Thus, we remove the more detailed accounts (```vC```, ```vC_tax```, ```gc```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b36f79e-cf84-4072-b633-96c131c4d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(t0, tE+1):\n",
    "    for k in ('gc','vC','vC_tax'):\n",
    "        del(dbs[t].series[k])\n",
    "    # Remove zeros:\n",
    "    [dbs[t].__setitem__(k, dbs[t].get(k)[dbs[t].get(k)!=0]) for k in ('vD','vD_inv','vD_dur','vD_depr','vTax')];    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33435c52-6f14-4378-a7f7-b93d8cd6abeb",
   "metadata": {},
   "source": [
    "## 5. Process data on durables, investments, and depreciation rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23002abe-acad-4686-b611-aa0abcb963db",
   "metadata": {},
   "source": [
    "* Depreciation of durables are translated to rates. \n",
    "* Distinguish between investment goods and durables: Define investment goods with syntax ```I_x``` for durable x.\n",
    "* Define the mapping dur2inv and relevant subsets (```dur_p``` and ```inv_p```)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367ecb3f-82e6-424c-b241-79f5815d6c94",
   "metadata": {},
   "source": [
    "*NB: Only run this cell once.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c62596c-7ef0-44a2-bf61-ce0d82debaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(t0, tE+1):\n",
    "    db = dbs[t]\n",
    "    db['rDepr'] = db.get('vD_depr') / (db.get('vD_dur').replace(0,1))\n",
    "    db['dur2inv'] = pd.MultiIndex.from_frame(db.get('vD_dur').index.to_frame(index = False).assign(nn = lambda x: 'I_'+x['n'])).reorder_levels(['s','n','nn'])\n",
    "    db['dur_p'] = db.get('dur2inv').droplevel('nn').unique() # what variables are durables (K)\n",
    "    db['inv_p'] = db.get('dur2inv').droplevel('n').unique().rename({'nn':'n'}) # what variables are investment goods (I)\n",
    "    db.get('vD_inv').index = db.get('vD_inv').index.set_levels('I_'+db.get('vD_inv').index.levels[1], level=1)\n",
    "    db['vD'] = db.get('vD_inv').combine_first(db.get('vD')).combine_first(db.get('vD_dur'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377f5c56-4e5d-4fbd-9bf7-ea0a9b9d78bf",
   "metadata": {},
   "source": [
    "*Clean up data:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f45aa77e-8ae8-4e4c-9bd6-aeaf4123c6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in ('vD_inv','vD_dur','vD_depr'):\n",
    "#     del(db.series[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67936199-b61b-4c52-b831-e84ddff0fb68",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. Eliminate small and negative values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acbbd51-8c53-450e-9158-12d47bef9cca",
   "metadata": {},
   "source": [
    "We create RAS-like adjustments *within* a number of blocks. We keep the sub-totals fixed in the following blocks:\n",
    "* Block A and I: Input-output from/to domestic production sectors (```n_p,s_p```) and the domestic investment sectors.\n",
    "* Block B and J: Domestic production and investment sectors' demand for imported goods (```n_F, s_p, s_i```). For this block, we do not require row-sums to be the same before and after. The implication is that imports of a specific type $n^F_i$ may not be the same after the adjustment.\n",
    "\n",
    "We do not make any adjustments to consumption components (in particular because there are not sufficient with consumption categories to balance the blocks). This approach ensures that most totals are the same - e.g. total imports per sector - is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c1d5cc1-bad6-471a-8c49-f7dbf565a438",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = gams.GamsWorkspace(working_directory=d['work']) # specify where you want to run the GAMS models from (here the repository referred to in d['work'])\n",
    "threshold = 1 # anything below 1 million is removed from the data\n",
    "for t in range(t0,tE+1):\n",
    "    db = dbs[t]\n",
    "    ras_settings = IOfunctions.standardCleanSettings(db, threshold)\n",
    "    # Run RAS adjustment:\n",
    "    vs, ms = {}, {}\n",
    "    for k,v in ras_settings.items():\n",
    "        vs[k] = RAS.shareRAS(v['v0'], v['vBar'], **v['kwargs']) # Initialize small gams model\n",
    "        vs[k].compile() # set up model\n",
    "        vs[k].write(); # write gams code\n",
    "        ms[k] = vs[k].run(exportTo = d['work'], ws = ws) # solve\n",
    "    gpyDB.add_or_merge_vals(db, pd.concat([ms[k].out_db.get('vD') for k in ms]+[ras_settings[k]['vBar'] for k in ras_settings],axis=0), name = 'vD') # add data to database\n",
    "    # Remove zero values and residual income category:\n",
    "    db['vD'] = adj.rc_pd(db.get('vD')[db.get('vD')!=0], ('not', pd.Index(['resIncome'], name = 'n')))\n",
    "    # Rescale values, divide by 10000 (measure in 10's of billions DKK):\n",
    "    [db.__setitem__(k, db.get(k)/10000) for k in [i for i in db.getTypes(['variable','parameter']) if i.startswith('v')]+['TotalTax']];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db7a355-a87a-4d2c-85a2-79d11581a969",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 7. Create variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018c574b-447f-4226-b085-9d200431b0c8",
   "metadata": {},
   "source": [
    "At this stage, we define variables that'll eventually be relevant in the model. This includes distinguishing between quantities and values, adding prices, effective tax rates, and similar. For each year, this creates the variables:\n",
    "* ```vS[s,n]```: The value of supply from sector $s$ of goods type $n$ (for the most part $s=n$ in this simple model; this may differ e.g. for households or sectors with multiple outputs).\n",
    "* ```p[n]```: The market equilibrium price on goods $n$. If no data has been provided, we default to $p=1$ for all goods.\n",
    "* ```qD[s,n]```: The quantity of demand from sector $s$ of goods type $n$. This is *always* defined as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b4e79f3-3315-42b7-a76c-c0e15229d926",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(t0, tE+1):\n",
    "    model_vS(dbs[t]) # add value of supply\n",
    "    model_p(dbs[t]) # add price vector if non has been provided\n",
    "    model_durables(dbs[t], glbls[t]) # add qD for durables and static user cost price (pD_dur)\n",
    "    model_quantNonDurables(dbs[t]) # add qD, qS for non-durables    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce140c5-02cf-4be4-ab66-4a9eeb16545a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 8. Create general mappings and subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f2a77da-f736-4e4c-8786-0e93110bcfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(t0,tE+1):\n",
    "    db = dbs[t]\n",
    "    db['nEqui'] = db['vS'].index.levels[-1] # what levels do the model need to identify an equilibrium for.\n",
    "    db['d_qS']  = db['vS'].index # what (s,n) combinations does supply come from\n",
    "    db['d_qD'] = adj.rc_pd(db['vD'], db['nEqui']).index # what (s,n) combinations does demand come from\n",
    "    db['d_qSEqui'] = adj.rc_pd(db['d_qS'].vals, ('not', db['s_HH'])) # Going from partial to general equilibrium, what 'qS' values should be endogenized\n",
    "    db['d_pEqui']  = pd.Index(['L'], name = 'n') # Going from partial to general equilibrium, what 'p' values should be endogenized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014fb6e9-b34b-4a70-9283-07e4438ffa8c",
   "metadata": {},
   "source": [
    "### 8.2. Trade mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c72877-5c9f-4bcc-b71b-a6a8a491332f",
   "metadata": {},
   "source": [
    "Define the mappings:\n",
    "* ```dom2for[n,nn]```: Mapping from domestic to the equivalent foreign goods (with syntax ```x,x_F```).\n",
    "* ```dExport[s,n]```: Foreign sectors' demand for domestic goods.\n",
    "* ```dImport[s,n,nn]```: sector, domestic good, foreign good combinations in data - i.e. where a sector demands both domestic and foreign type of product.\n",
    "* ```dImport_dom[s,n]```: sector, domestic good combination (s,n) where the sector only demands the domestic and not the corresponding foreign good.\n",
    "* ```dImport_for[s,n]```: sector, foreign good combinations (s,n) where the sector only demand the foreign and not the corresponding domestic good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab9e8c8c-ab09-4bc4-88e8-38a8db4ecc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(t0,tE+1):\n",
    "    db = dbs[t]\n",
    "    db['dom2for'] = pd.MultiIndex.from_arrays([db.get('n_p').sort_values(), db.get('n_F').sort_values().rename('nn')])\n",
    "    db['dExport'] = adj.rc_pd(db.get('vD'), db.get('s_f')).index # foreign sectors' demand for domestic goods\n",
    "    vD_dom = adjMultiIndex.applyMult(adj.rc_pd(db.get('vD'), db.get('n_p')), db.get('dom2for')) # demand for domestic goods mapped to foreign goods types\n",
    "    vD_for = adj.rc_pd(db.get('vD'), db.get('n_F')).rename_axis(index={'n':'nn'}) # demand for foreign goods\n",
    "    db['dImport'] = adj.rc_pd(vD_dom, vD_for).reorder_levels(['s','n','nn']).index\n",
    "    db['dImport_dom'] = adj.rc_pd(vD_dom, ('not', vD_for)).droplevel('nn').reorder_levels(['s','n']).index\n",
    "    db['dImport_for'] = adj.rc_pd(vD_for, ('not', db['dImport'])).index.rename(['s','n']).reorder_levels(['s','n'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8a4527-8e61-4886-8b38-7fbdec3b8392",
   "metadata": {
    "tags": []
   },
   "source": [
    "## X. Export:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f103c82a-f250-403c-8ee7-687075df03a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(t0,tE+1):\n",
    "    db = dbs[t]\n",
    "    aggregateDB.readSets(db) # read sets from the symbols in data\n",
    "    db.export(repo = d['processedData'])\n",
    "    with open(f\"{d['processedData']}\\\\glob_{t}\", \"wb\") as file:\n",
    "        pickle.dump(glbls[t],file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
