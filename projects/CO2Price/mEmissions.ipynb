{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f367abe-f37b-4ef6-8f06-3b0ab1f977d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db79358-8349-4412-9100-a824cc9cee2b",
   "metadata": {},
   "source": [
    "# Emissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8257e0-839c-4758-9f9a-ae3a091bc419",
   "metadata": {},
   "source": [
    "## 1. Data/settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3141bd76-5cb1-4c7f-b936-050169dc9c7b",
   "metadata": {},
   "source": [
    "If the local variable $t$ has been defined already, the notebook is running from another notebook. If this is not the case, a number of \"local\" methods have to be carried out before solving the model (e.g. setting up the relevant IO data set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e75af0f7-6108-406f-ad64-efdfa69f26e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file _gams_py_gdb0.gdx is still active and was not deleted.\n",
      "The file _gams_py_gdb2.gdx is still active and was not deleted.\n",
      "The file _gams_py_gdb3.gdx is still active and was not deleted.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    t = t\n",
    "except NameError:\n",
    "    clean_up = True\n",
    "    %run StdPackages.ipynb\n",
    "    name, t = 'full', 2019\n",
    "    ws = gams.GamsWorkspace(working_directory=d['work']) # specify where you want to run the GAMS models from (here the repository referred to in d['work'])\n",
    "    with open(f\"{d['processedData']}\\\\glob_{t}\",\"rb\") as file: # load global settings anmed glob_name\n",
    "        glob=pickle.load(file)\n",
    "    db_IO = GpyDB(pickle_path = os.path.join(d['processedData'], f'{name}_{t}')) # load IO database named IO_name\n",
    "    addTimeToDb(db_IO, glob.db['t'].vals, exceptions = ['sigma'])\n",
    "module = '_'.join([name,str(t),'emissions'])\n",
    "db_IO0 = db_IO.copy() # create copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f12c6f-5b05-46f3-a13e-f9a710aafd33",
   "metadata": {},
   "source": [
    "*Define new sets:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b038817e-5968-4ba4-8ff6-122ed7dc946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.db['tx20E'] = gpy(adj.rc_pd(glob.db['t'], ('not' , glob.db['t'].vals[0:2].union(glob.db['tE']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fef36e-3330-450c-8565-394d923dc27a",
   "metadata": {},
   "source": [
    "Initialize module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11a8882c-79b6-474e-ae39-7c7607d453f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = mEmissions.emissionTarget(name=module, glob = glob, s_kwargs = {'db': db_IO0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961a0d75-4407-4b77-913e-cf79a835c356",
   "metadata": {},
   "source": [
    "1. Load technology data,\n",
    "2. subset to relevant years,\n",
    "3. extrapolate data if needed (if model data goes beyond technical data),\n",
    "4. adjust the unit cost measure of the technologies; recall, the tax measures 10 billion DKK / M1990-level emission whereas the technology data measures DKK/ton CO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6060752-b7c8-4f8c-8953-e9c643543166",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech = read.SeriesDB_from_wb(os.path.join(d['rawData'], 'abatementData.xlsx'), {'variables': ['EOP']})\n",
    "[tech.__setitem__(k, adj.rc_pd(tech[k], glob.db['t'])) for k in tech.database];\n",
    "[tech.__setitem__(k, auxiliary.extrapolateUpper(tech.get(k), glob.db['tE'].vals[0])) for k in tech.database];\n",
    "tech['tech'] = tech.get('techCost').index.levels[0]\n",
    "tech['techCost'] = tech.get('techCost') * (glob.db['M1990'].vals * 1e6) / 1e10\n",
    "tech['DACCost']  = tech.get('DACCost') * (glob.db['M1990'].vals * 1e6) / 1e10\n",
    "robust.robust_merge_dbs(M.s.db, tech) # "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69a486e-4953-4f04-883e-4e80fd2267b3",
   "metadata": {},
   "source": [
    "4. define average CO2 tax,\n",
    "5. map these to sector/goods taxation (using exogenous parameter ```tauDist```),\n",
    "6. define aggregate CO2 emissions (sum over sector, goods level),\n",
    "6. define smoothing parameters in abatement technologies as 1/10 of the current tax level,\n",
    "7. set the ```qCO2Base``` as the emission level in 1990 (here manually, redo this once we've implemented the scaling of emissions),\n",
    "8. set the ```tauCO2Base``` as the emission tax level in the baseline year,\n",
    "9. set the ```softConstr``` level as the level of emissions in the baseline year / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "768b0df4-02e5-49c1-b995-d99b4b96759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "M.s.db['uCO2'] = adj.rc_pd(db_IO.get('qCO2'), db_IO['s_p'])/adj.rc_pd(db_IO['qS'], db_IO['s_p']) # CO2 shares\n",
    "M.s.db['uCO20'] = M.get('uCO2').rename('uCO20')\n",
    "M.s.db['uCO2Calib'] = pd.Series(0, index = db_IO.get('dqCO2'))\n",
    "M.s.db['tauCO2agg'] = (db_IO.get('tauCO2') * db_IO.get('qCO2')).groupby('t').sum() / (db_IO.get('qCO2').groupby('t').sum())\n",
    "M.s.db['tauDist'] = db_IO.get('tauCO2')/M.get('tauCO2agg')\n",
    "M.s.db['qCO2agg'] = db_IO.get('qCO2').groupby('t').sum()\n",
    "M.s.db['DACSmooth'] = M.get('tauCO2agg').xs(glob.db['t0'].vals[0])/25\n",
    "M.s.db['techSmooth'] = pd.Series(M.get('DACSmooth'), index = tech.get('techPot').index.levels[0])\n",
    "M.s.db['qCO2Base'] = 1\n",
    "M.s.db['tauCO2Base']= M.get('tauCO2agg').xs(glob.db['t0'].vals[0])\n",
    "M.s.db['softConstr']= 1/25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd56db3-69d7-4d9c-a833-b573bfefa877",
   "metadata": {},
   "source": [
    "Set emission target: To start with, just define the targets as the path of actual emissions (load path later). Define subset tTarget[t] as the index over targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "256477cb-1a72-47a9-b81e-fb17de13fb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "M.s.db['qCO2Target'] = pyDatabases.pdSum(db_IO.get('qCO2'), ['s','n']).rename('qCO2Target')\n",
    "M.readTargetSubsets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338574ef-d53d-43c3-9041-131ac661bc83",
   "metadata": {},
   "source": [
    "Initialize, write, and solve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9494b7b-e0e6-41bf-a138-33099327bd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "M.compile(initDB=False);\n",
    "M.write();\n",
    "m = M.run(exportTo = d['work'],ws=ws) # solve the \"model\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d88147-9057-4788-85aa-e6e496333ed6",
   "metadata": {},
   "source": [
    "Export:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea041c20-5565-4f7d-8fbe-4524ad35d24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "M.s.db = m.out_db\n",
    "with open(os.path.join(d['modules'], M.name), \"wb\") as file:\n",
    "    pickle.dump(M,file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
